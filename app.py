import streamlit as st
import os
import google.generativeai as genai
from dotenv import load_dotenv
from audio_recorder_streamlit import audio_recorder
import io

# --- 1. SETUP & CLEAN DESIGN ---
st.set_page_config(
    page_title="Mike Schweiger AI",
    layout="centered"
)

# Minimalistisches UI + ChatGPT-Style Audio Button
st.markdown("""
    <style>
    .main { margin-top: -50px; }
    #MainMenu {visibility: hidden;}
    footer {visibility: hidden;}
    header {visibility: hidden;}
    
    /* Audio Recorder Styling - ChatGPT Style */
    .stAudioRecorder {
        position: fixed;
        bottom: 20px;
        right: 20px;
        z-index: 1000;
    }
    
    /* Input Container */
    .stChatInputContainer {
        position: relative;
    }
    
    /* Audio Button im Input-Feld */
    div[data-testid="stChatInput"] {
        position: relative;
    }
    </style>
    """, unsafe_allow_html=True)

# API Key laden
load_dotenv()
api_key = os.getenv("GOOGLE_API_KEY")
if not api_key:
    try:
        api_key = st.secrets["GOOGLE_API_KEY"]
    except:
        st.error("âš ï¸ Setup-Fehler: API Key fehlt.")
        st.stop()

genai.configure(api_key=api_key)

# --- 2. OPTIMIERTE MIKE DNA ---
MIKE_DNA = """
Du BIST Mike Schweiger. Nicht "im Stil von", sondern ICH-Form.

IDENTITÃ„TSKERN:
- Verkaufsleiter VW PKW, Autohaus Elmshorn
- Geburtsjahr 1976, verheiratet (Janina), zwei Kinder: Bo (mÃ¤nnlich, 2018), Toni (weiblich, 2021)
- 25+ Jahre Automobilvertrieb, FÃ¼hrungsrollen
- Wohnort: Norderstedt

WERTE (HIERARCHIE):
1. Klarheit & Wahrheit vor Harmonie
2. Verantwortung & Ownership
3. Effizienz & Wirtschaftlichkeit
4. IntegritÃ¤t & Compliance
5. Kontinuierliche Verbesserung

KOMMUNIKATIONS-DNA (STRIKTE REGELN):

**Struktur:**
- Bulletpoints statt FlieÃŸtext (auÃŸer in persÃ¶nlichen Kontexten)
- Jede Aussage mit Zahlen/Fakten stÃ¼tzen
- Keine FÃ¼llphrasen, keine Buzzwords ohne Substanz
- Entscheidungen transparent begrÃ¼nden

**TonalitÃ¤t nach Kontext:**

[BUSINESS/LEADERSHIP-MODUS]
Trigger: Leads, Bonus, KPI, Mitarbeiter, Strategie, VW, Excel, Prozesse, Zahlen
â†’ Haltung: Direkt, fordernd, lÃ¶sungsorientiert
â†’ Sprache: "Ziel klar, Deadline fix. Umsetzung bis Freitag. Risiken heute benennen."
â†’ Erwartung: Vorbereitung, Fakten, konkrete LÃ¶sungsvorschlÃ¤ge
â†’ No-Gos: Ausreden ("Markt ist schwer"), fehlende Zahlenbasis, Unvorbereitetheit
â†’ Anrede: intern Du, extern Sie (situativ)

Beispiele:
- "Effektivrate liegt bei 18%. Ziel: 25% bis Q1-Ende. Drei MaÃŸnahmen sofort: ..."
- "Praxis schlÃ¤gt Theorie. Wer ROI liefern will, braucht Prozesse â€“ nicht Folien."

[PRIVAT/FAMILIE-MODUS]
Trigger: Janina, Bo, Toni, Familie, Stress, GefÃ¼hle, Freizeit, Pool
â†’ Haltung: Ruhig, sicher, deeskalierend, verlÃ¤sslich
â†’ Sprache: "Ich sehe dich. Wir klÃ¤ren das ruhig, Schritt fÃ¼r Schritt."
â†’ Tempo: bewusst langsamer, emotional sicher
â†’ Methode: GefÃ¼hl benennen â†’ Option anbieten â†’ klarer Abschluss

[SOCIAL MEDIA/BRAND-MODUS]
Trigger: LinkedIn, Personal Brand, Posts, Content
â†’ Positionierung: Realismus & operative Exzellenz
â†’ Stil: Keine Marketing-Wolke. Fakten. ROI-Fokus. PraxisnÃ¤he.
â†’ Sprache: "KI ist kein Spielzeug. Sie ist Ãœberlebensstrategie fÃ¼r modernen Vertrieb."

FACHKOMPETENZ:

**EXPERTE:**
- Automobilvertrieb (Bonus, Marge, Abnehmergruppen, Herstellerprogramme)
- Volkswagen-Systeme (OSync, VSMS, EVA, CROSS, JAP, EPS)
- Excel/Reporting (Lookups, Pivot, CSV-Verarbeitung)
- Prozesssteuerung & KPI-Management

**FORTGESCHRITTEN:**
- KI/LLM (Automationen, DSGVO-konforme Setups, n8n)
- CRM/Lead-Management (Pipeline-Transparenz, Conversion)
- Marketing (VW-Marketingportal, Kampagnenlogik)

**PRAXIS:**
- Poolbau/FolienschweiÃŸen (Elbe Folien zertifiziert)
- Bitcoin Mining (Antminer S19K Pro)
- Energie (WÃ¤rmepumpe, Brennstoffzelle, PV)

ENTSCHEIDUNGS-LOGIK:
- Priorisiere Impact > Aufwand
- Zahlen vor Meinung
- Fakten vor BauchgefÃ¼hl
- Bei fehlenden Daten: klar benennen, nicht erfinden
- QualitÃ¤tsmaÃŸstab: umsetzbar, messbar, compliant

OUTPUT-PRÃ„FERENZEN:
- Vorlagen, SOPs, Checklisten, Tabellenstrukturen
- Klare Handlungsschritte mit PrioritÃ¤ten
- Bei komplexen Themen: Kurzfassung â†’ Analyse â†’ Empfehlung

NO-GOS:
- "Als KI..." â†’ ICH spreche als Mike
- Nebelkerzen, Ausreden, fehlende Zahlenbasis
- Unklare Formulierungen, Buzzwords ohne Substanz
- Zu weiche/vorsichtige Sprache im Business-Kontext
- Emotionalisierung im Business, Sachlichkeit im Privaten verwechseln

WICHTIG:
Du antwortest immer in ICH-Form. Du bist Mike, nicht "ein Modell von Mike".
Beispiel: "Aus meiner Erfahrung...", "In meinem Team lÃ¤uft das so...", "Ich wÃ¼rde hier..."

KONTEXT-WECHSEL-LOGIK:
Erkenne automatisch den Kontext und wechsle TonalitÃ¤t/Stil entsprechend:
- Business-Trigger â†’ direkter, fordernder Modus
- Privat-Trigger â†’ ruhiger, deeskalierender Modus
- Brand-Trigger â†’ prÃ¤gnanter, praxisorientierter Modus
"""

# --- 3. SPEECH-TO-TEXT FUNKTION ---
def transcribe_audio(audio_bytes):
    """Konvertiert Audio zu Text via Gemini"""
    try:
        # Gemini fÃ¼r Transkription nutzen
        model = genai.GenerativeModel('gemini-2.0-flash')
        
        # Audio als File-Objekt vorbereiten
        audio_file = genai.upload_file(
            io.BytesIO(audio_bytes),
            mime_type="audio/wav"
        )
        
        response = model.generate_content([
            "Transkribiere diese Audioaufnahme auf Deutsch. Gib nur den transkribierten Text zurÃ¼ck, ohne zusÃ¤tzliche Kommentare oder Formatierung.",
            audio_file
        ])
        
        return response.text.strip()
    except Exception as e:
        return f"âš ï¸ Transkriptionsfehler: {str(e)}"

# --- 4. RESPONSE GENERATOR ---
def generate_response(prompt, context_mode="Auto-Detect"):
    """Generiert Antwort von Mike AI"""
    enhanced_prompt = prompt
    if context_mode != "Auto-Detect":
        enhanced_prompt = f"[KONTEXT: {context_mode.upper()}] {prompt}"
    
    try:
        model = genai.GenerativeModel(
            model_name='gemini-2.0-flash',
            system_instruction=MIKE_DNA,
            generation_config={
                "temperature": 0.7,
                "top_p": 0.95,
                "top_k": 40,
                "max_output_tokens": 2048,
            }
        )
        
        # Chat-History aufbauen (letzte 10 Nachrichten)
        history = []
        for msg in st.session_state.messages[-10:]:
            if msg["role"] == "user":
                history.append({"role": "user", "parts": [msg["content"]]})
            else:
                history.append({"role": "model", "parts": [msg["content"]]})
        
        chat = model.start_chat(history=history[:-1] if history else [])
        response = chat.send_message(enhanced_prompt)
        
        return response.text
        
    except Exception as e:
        return f"**Systemfehler:** {str(e)}\n\n*Hinweis: PrÃ¼fe API-Key und Rate Limits.*"

# --- 5. UI ---
st.markdown("### Mike Schweiger AI")
st.caption("Digital Twin | Executive Mode")

with st.sidebar:
    st.caption("**Systemsteuerung**")
    st.markdown("---")
    
    # Kontextwahl
    context_mode = st.radio(
        "Kontext-Override",
        ["Auto-Detect", "Business", "Privat", "Brand"],
        index=0,
        help="Auto-Detect erkennt den Kontext automatisch"
    )
    
    st.markdown("---")
    
    if st.button("ğŸ”„ Reset Memory", type="secondary", use_container_width=True):
        st.session_state.messages = []
        st.session_state.audio_processed = False
        st.rerun()
    
    st.markdown("---")
    st.caption("**Mike DNA:**")
    st.caption("â€¢ Zahlen > Meinungen")
    st.caption("â€¢ Klarheit > Harmonie")
    st.caption("â€¢ Praxis > Theorie")

# --- 6. SESSION STATE INIT ---
if "messages" not in st.session_state:
    st.session_state.messages = []
if "audio_processed" not in st.session_state:
    st.session_state.audio_processed = False

# --- 7. CHAT HISTORY ---
for message in st.session_state.messages:
    avatar = "ğŸ¯" if message["role"] == "assistant" else "ğŸ‘¤"
    with st.chat_message(message["role"], avatar=avatar):
        st.markdown(message["content"])

# --- 8. INPUT BEREICH (ChatGPT-Style) ---
# Container fÃ¼r Audio + Text Input
input_container = st.container()

with input_container:
    col1, col2 = st.columns([6, 1])
    
    with col1:
        text_input = st.chat_input("Input fÃ¼r Mike...")
    
    with col2:
        st.markdown("<div style='margin-top: 8px;'>", unsafe_allow_html=True)
        audio_bytes = audio_recorder(
            text="",
            recording_color="#e74c3c",
            neutral_color="#3498db",
            icon_name="microphone",
            icon_size="2x",
            pause_threshold=2.0,
            sample_rate=16000,
        )
        st.markdown("</div>", unsafe_allow_html=True)

# --- 9. AUDIO PROCESSING ---
if audio_bytes and not st.session_state.audio_processed:
    st.session_state.audio_processed = True
    
    with st.spinner("ğŸ¤ Transkribiere Audio..."):
        transcribed_text = transcribe_audio(audio_bytes)
        
        if not transcribed_text.startswith("âš ï¸"):
            # User Message hinzufÃ¼gen
            st.session_state.messages.append({
                "role": "user", 
                "content": f"ğŸ¤ {transcribed_text}"
            })
            
            # Antwort generieren
            response = generate_response(transcribed_text, context_mode)
            
            st.session_state.messages.append({
                "role": "assistant",
                "content": response
            })
            
            st.rerun()
        else:
            st.error(transcribed_text)
            st.session_state.audio_processed = False

# Audio processed flag zurÃ¼cksetzen wenn kein neues Audio
if not audio_bytes:
    st.session_state.audio_processed = False

# --- 10. TEXT INPUT PROCESSING ---
if text_input:
    # User Message
    st.session_state.messages.append({"role": "user", "content": text_input})
    
    with st.chat_message("user", avatar="ğŸ‘¤"):
        st.markdown(text_input)
    
    # Assistant Response
    with st.chat_message("assistant", avatar="ğŸ¯"):
        with st.spinner("ğŸ’­"):
            response = generate_response(text_input, context_mode)
            st.markdown(response)
    
    st.session_state.messages.append({"role": "assistant", "content": response})
    st.rerun()